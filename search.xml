<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[时间复杂度和空间复杂度]]></title>
    <url>%2F2020%2F05%2F12%2F%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%92%8C%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。那如何来衡量你编写的算法代码的执行效率呢？这里就要用到我们今天要讲的内容：时间、空间复杂度分析。 为什么需要复杂度分析通常，对于一个给定的算法，我们要做两项分析。第一是从数学上证明算法的正确性，这一步主要用到形式化证明的方法及相关推理模式，如循环不变式、数学归纳法等。而在证明算法是正确的基础上，第二部就是分析算法的时间复杂度。算法的时间复杂度反映了程序执行时间随输入规模增长而增长的量级，在很大程度上能很好反映出算法的优劣与否。因此，作为程序员，掌握基本的算法时间复杂度分析方法是很有必要的。 算法执行时间需通过依据该算法编制的程序在计算机上运行时所消耗的时间来度量。而度量一个程序的执行时间通常有两种方法。 事后统计的方法这种方法主要是通过设计好的测试程序和数据，利用计算机计时器对不同算法编制的程序的运行时间进行比较，从而确定算法效率的高低。但这种方法显然是有很大缺陷的： (1). 必须依据算法事先编制好程序，这通常需要花费大量的时间和精力。如果编制出来发现它根本是很糟糕的算法，不是竹篮打水一场空吗？ (2). 时间的比较依赖计算机硬件和软件等环境因素，有时会掩盖算法本身的优劣。要知道，现在的一台四核处理器的计算机，跟当年286、386、486等老爷爷辈的机器相比，在处理算法的运算速度上，是不能相提并论的；而所用的操作系统、编译器、运行框架等软件的不同，也可以影响它们的结果；就算是同一台机器，CPU使用率和内存占用情况不一样，也会造成细微的差异。 (3). 算法的测试数据设计困难，并且程序的运行时间往往还与测试数据的规模有很大关系，效率高的算法在小的测试数据面前往往得不到体现。比如10个数字的排序，不管用什么算法，差异几乎是零。而如果有一百万个随机数字排序，那不同算法的差异就非常大了。那么我们为了比较算法，到底用多少数据来测试，这是很难判断的问题。 基于事后统计方法有这样那样的缺陷，我们考虑不予采纳。 事前分析估算的方法因事后统计方法更多的依赖于计算机的硬件、软件等环境因素，有时容易掩盖算法本身的优劣。因此人们常常采用事前分析估算的方法。 在编写程序前，依据统计方法对算法进行估算。一个用高级语言编写的程序在计算机上运行时所消耗的时间取决于下列因素： (1). 算法采用的策略、方法；(2). 编译产生的代码质量；(3). 问题的输入规模；(4). 机器执行指令的速度。 一个算法是由控制结构（顺序、分支和循环3种）和原操作（指固有数据类型的操作）构成的，则算法时间取决于两者的综合效果。为了便于比较同一个问题的不同算法，通常的做法是，从算法中选取一种对于所研究的问题（或算法类型）来说是基本操作的原操作，以该基本操作的重复执行的次数作为算法的时间量度。 函数的渐近增长算法对比1 我们现在来判断一下，以下两个算法A和B哪个更好。假设两个算法的输入规模都是n，算法A要做2n+3次操作，你可以理解为先有一个n次的循环，执行完成后，再有一个n次循环，最后有三次赋值或运算，共2n+3次操作。算法B要做3n+1次操作。你觉得它们谁更快呢？准确说来，答案是不一定的，如下图所示。 当n=1时，算法A效率不如算法B（次数比算法B要多一次）。而当n=2时，两者效率相同；当n&gt;2时，算法A就开始优于算法B了，随着n的增加，算法A比算法B越来越好了（执行的次数比B要少）。于是我们可以得出结论，算法A总体上要好过算法B。 此时我们给出这样的定义，输入规模n在没有限制的情况下，只要超过一个数值N，这个函数就总是大于另一个函数，我们称函数是渐近增长的。函数的渐近增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n&gt;N，f(n)总是比g(n)大，那么，我们说f(n)的增长渐近快于 从中我们发现，随着n的增大，后面的+3还是+1其实是不影响最终的算法变化的，例如算法A′与算法B′，所以，我们可以忽略这些加法常数项。 算法对比2我们来看第二个例子，算法C是4n+8，算法D是$2n^2+1$，如下图所示。 当n≤3的时候，算法C要差于算法D（因为算法C次数比较多），但当n&gt;3后，算法C的优势就越来越优于算法D了，到后来更是远远胜过。而当后面的常数去掉后，我们发现其实结果没有发生改变。甚至我们再观察发现，哪怕去掉与n相乘的常数，这样的结果也没发生改变，算法C′的次数随着n的增长，还是远小于算法D′。也就是说，与最高次项相乘的常数并不重要。 算法对比3我们再来看第三个例子。算法E是$2n^2+3n+1$，算法F是$2n^3+3n+1$，如下图所示。 当n=1的时候，算法E与算法F结果相同，但当n&gt;1后，算法E的优势就要开始优于算法F，随着n的增大，差异非常明显。通过观察发现，最高次项的指数大的，函数随着n的增长，结果也会变得增长特别快。 算法对比4我们来看最后一个例子。算法G是$2n^2$，算法H是3n+1，算法I是$2n^2+3n+1$，如下图所示。 这组数据应该就看得很清楚。当n的值越来越大时，你会发现，3n+1已经没法和2n2的结果相比较，最终几乎可以忽略不计。也就是说，随着n值变得非常大以后，算法G其实已经很趋近于算法I。于是我们可以得到这样一个结论，判断一个算法的效率时，函数中的常数和其他次要项常常可以忽略，而更应该关注主项（最高阶项）的阶数。 判断一个算法好不好，我们只通过少量的数据是不能做出准确判断的。根据刚才的几个样例，我们发现，如果我们可以对比这几个算法的关键执行次数函数的渐近增长性，基本就可以分析出：某个算法，随着n的增大，它会越来越优于另一算法，或者越来越差于另一算法。这其实就是事前估算方法的理论依据，通过算法时间复杂度来估算算法时间效率。 算法的时间复杂度算法的时间复杂度的定义在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度，记作：T(n)=O(f(n))。它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中f(n)是问题规模n的某个函数。 这样用大写O( )来体现算法时间复杂度的记法，我们称之为大O记法。一般情况下，随着n的增大，T(n)增长最慢的算法为最优算法。O(1)叫常数阶、O(n)叫线性阶、O($n^2$)叫平方阶，当然，还有其他的一些阶，我们之后会介绍。 推导大O阶方法那么如何分析一个算法的时间复杂度呢？即如何推导大O阶呢？我们给出了下面的推导方法，基本上，这也就是总结前面我们举的例子。推导大O阶： 1．用常数1取代运行时间中的所有加法常数。2．在修改后的运行次数函数中，只保留最高阶项。3．如果最高阶项存在且不是1，则去除与这个项相乘的常数。 常见时间复杂度常数阶123int sum = 0 ; n = 100; /*执行一次*/sum = (1+n)*n/2; /*执行一次*/printf("%d",sum); /*执行一次*/ 这个算法的运行次数函数是f(n)=3。根据我们推导大O阶的方法，第一步就是把常数项3改为1。在保留最高阶项时发现，它根本没有最高阶项，所以这个算法的时间复杂度为O(1)。 另外，我们试想一下，如果这个算法当中的语句sum=(1+n)*n/2有10句，即：123456789101112int sum = 0 ; n = 100; /*执行一次*/sum = (1+n)*n/2; /*执行第1次*/sum = (1+n)*n/2; /*执行第2次*/sum = (1+n)*n/2; /*执行第3次*/sum = (1+n)*n/2; /*执行第4次*/sum = (1+n)*n/2; /*执行第5次*/sum = (1+n)*n/2; /*执行第6次*/sum = (1+n)*n/2; /*执行第7次*/sum = (1+n)*n/2; /*执行第8次*/sum = (1+n)*n/2; /*执行第9次*/sum = (1+n)*n/2; /*执行第10次*/printf("%d",sum); /*执行一次*/ 事实上无论n为多少，上面的两段代码就是3次和12次执行的差异。这种与问题的大小无关（n的多少），执行时间恒定的算法，我们称之为具有O(1)的时间复杂度，又叫常数阶。注意：不管这个常数是多少，3或12，都不能写成O(3)、O(12)，而都要写成O(1)，这一点要特别注意。此外，对于分支结构而言，无论真假执行的次数都是恒定不变的，不会随着n的变大而发生变化，所以单纯的分支结构（不在循环结构中），其时间复杂度也是O(1)。 线性阶线性阶的循环结构会复杂很多。要确定某个算法的阶次，我们常常需要确定某个特定语句或某个语句集运行的次数。因此，我们要分析算法的复杂度，关键就是要分析循环结构的运行情况。下面这段代码，它的循环的时间复杂度为O(n)，因为循环体中的代码须要执行n次。 12345int i;for (i = 0; i &lt; n; i++)&#123; /* 时间复杂度为O(1)的程序步骤序列 */&#125; 对数阶下面的这段代码，时间复杂度又是多少呢？123456int count = 1;while (count &lt; n)&#123; count = count * 2; /* 时间复杂度为O(1)的程序步骤序列 */&#125;由于每次count乘以2之后，就距离n更近了一分。也就是说，有多少个2相乘后大于n，则会退出循环。由$2^x=n$得到$x=\log_2n$。所以这个循环的时间复杂度为O($\log n$)。 平方阶下面例子是一个循环嵌套，它的内循环刚才我们已经分析过，时间复杂度为O(n)。 12345678int i, j;for (i = 0; i &lt; n; i++)&#123; for (j = 0; j &lt; n; j++) &#123; /* 时间复杂度为O(1)的程序步骤序列 */ &#125;&#125; 而对于外层的循环，不过是内部这个时间复杂度为O(n)的语句，再循环n次。所以这段代码的时间复杂度为O($n^2$)。 如果外循环的循环次数改为了m，时间复杂度就变为O(m×n)。12345678int i, j;for (i = 0; i &lt; m; i++)&#123; for (j = 0; j &lt; n; j++) &#123; /* 时间复杂度为O(1)的程序步骤序列 */ &#125;&#125;所以我们可以总结得出，循环的时间复杂度等于循环体的复杂度乘以该循环运行的次数。 那么下面这个循环嵌套，它的时间复杂度是多少呢？ 123456789int i, j;for (i = 0; i &lt; n; i++)&#123; /* 注意j = i 而不是0 */ for (j = i; j &lt; n; j++) &#123; /* 时间复杂度为O(1)的程序步骤序列 */ &#125;&#125; 由于当i=0时，内循环执行了n次，当i=1时，执行了n-1次，……当i=n-1时，执行了1次。所以总的执行次数为：$n+(n-1)+(n-1)+…+1 = n(n+1)/2 = n^2/2 + n/2$用我们推导大O阶的方法，第一条，没有加法常数不予考虑；第二条，只保留最高阶项，因此保留n2/2；第三条，去除这个项相乘的常数，也就是去除1/2，最终这段代码的时间复杂度为O($n^2$)。 常见的时间复杂度 执行次数函数 阶 术语描述 12 O(1) 常数阶 2n+3 O(n) 线性阶 3n2 +2n+1 O($n^2$ ) 平方阶 5log2 n+20 O($\log n$) 对数阶 2n+3nlog2 n+19 O($n\log n$) nlogn阶 6n3+2n2 +3n+4 O($n^3$ ) 立方阶 2n O($2^n$ ) 指数阶 常用的时间复杂度所耗费的时间从小到大依次是：$O(1)&lt;O(\log n)&lt;O(n)&lt;O(n\log n)&lt;O(n^2)&lt;O(n^3)&lt;O(2^n)&lt;O(n!)&lt;O(n^n)$ 算法的空间复杂度算法的空间复杂度定义 一个程序的空间复杂度是指运行完一个程序所需内存的大小，利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。程序执行时所需存储空间包括以下两部分： （1）固定部分：这部分空间的大小与输入/输出的数据的个数多少、数值无关，主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间，这部分属于静态空间。（2）可变空间：这部分空间的主要包括动态分配的空间，以及递归栈所需的空间等，这部分的空间大小与算法有关。 我们在写代码时，完全可以用空间来换取时间，比如说，要判断某某年是不是闰年，你可能会花一点心思写了一个算法，而且由于是一个算法，也就意味着，每次给一个年份，都是要通过计算得到是否是闰年的结果。还有另一个办法就是，事先建立一个有2050个元素的数组（年数略比现实多一点），然后把所有的年份按下标的数字对应，如果是闰年，此数组项的值就是1，如果不是值为0。这样，所谓的判断某一年是否是闰年，就变成了查找这个数组的某一项的值是多少的问题。此时，我们的运算是最小化了，但是硬盘上或者内存中需要存储这2050个0和1。这是通过一笔空间上的开销来换取计算时间的小技巧。到底哪一个好，其实要看你用在什么地方。 算法的空间复杂度通过计算算法所需的存储空间实现，算法空间复杂度的计算公式记作：S(n)=O(f(n))，其中，n为问题的规模，f(n)为语句关于n所占存储空间的函数。 常见的空间复杂度常数阶 12345678910int fun(int n)&#123; int i，j，k，s; s=0; for (i=0;i&lt;=n;i++) for (j=0;j&lt;=i;j++) for (k=0;k&lt;=j;k++) s++; return(s);&#125; 由于算法中临时变量得个数与问题规模n无关，所以空间复杂度均为S(n) = O(1) 线性阶 1234567891011121314151617void fun(int a[]，int n，int k) //数组a共有n个元素&#123; int i; if (k==n-1) &#123; for (i=0;i&lt;n;i++) printf(“%d\n”，a[i]); //执行n次 &#125; else &#123; for (i=k;i&lt;n;i++) a[i]=a[i]+i*i; //执行n-k次 fun(a，n，k+1); &#125;&#125; 此方法属于递归算法，每次调用本身都要分配空间，fun(a,n,0)的空间复杂度为O(n)。S(n) = O(g(1*n))若写成非递归算法，代码一般可能比较长，算法本身占用的存储空间较多，但运行时将可能需要较少的存储单元。 常见数据结构的空间复杂度 时间复杂度、空间复杂度举例分析二分法查找二分查找的非递归算法123456789101112131415161718192021222324template&lt;typename T&gt; T* BinarySearch(T* array,int number,const T&amp; data) //data要查找的数，number查找范围长度，array要查找的数组&#123; assert(number&gt;=0); int left = 0; int right = number-1; while (right &gt;= left) &#123; int mid = (left&amp;right) + ((left^right)&gt;&gt;1); if (array[mid] &gt; data) &#123; right = mid - 1; &#125; else if (array[mid] &lt; data) &#123; left = mid + 1; &#125; else &#123; return (array + mid); &#125; &#125; return NULL; &#125; 分析：假设最坏情况下，循环X次之后找到，则：$2^x=n; x=\log_2n$循环的基本次数是$\log_2N$，所以: 时间复杂度是O(logN);由于辅助空间是常数级别的所以：空间复杂度是O(1); 二分查找的递归算法123456789101112131415161718template&lt;typename T&gt; T* BinarySearch(T* left,T* right,const T&amp; data) &#123; assert(left); assert(right); if (right &gt;=left) &#123; T* mid =left+(right-left)/2; if (*mid == data) return mid; else return *mid &gt; data ? BinarySearch(left, mid - 1, data) : BinarySearch(mid + 1, right, data); &#125; else &#123; return NULL; &#125; &#125; 假设最坏情况下，循环X次之后找到，则：$2^x=n; x=\log_2n$递归的次数和深度都是$\log_2N$,每次所需要的辅助空间都是常数级别的：时间复杂度:O(log2N)；空间复杂度：O(log2N )。 斐波那契数这里我借用百度百科上的解释：斐波那契数，亦称之为斐波那契数列（意大利语： Successione di Fibonacci)，又称黄金分割数列、费波那西数列、费波拿契数、费氏数列，指的是这样一个数列：0、1、1、2、3、5、8、13、21、……在数学上，斐波纳契数列以如下被以递归的方法定义：F0=0，F1=1，Fn=Fn-1+Fn-2（n&gt;=2，n∈N*），用文字来说，就是斐波那契数列列由 0 和 1 开始，之后的斐波那契数列系数就由之前的两数相加。特别指出：0不是第一项，而是第零项。在这个斐波那契数列中的数字，就被称为斐波那契数求第N个斐波那契数比较简单可以直接套用公式n = 0,1 时，fib(n) = 1；n &gt; =2 时，fib(n) = fib(n-2) + fib(n-1)在计算时有两种算法：递归和非递归。如下： 第N个斐波那契数的非递归算法12345678910111213141516171819202122232425//非递归算法long long fib1(size_t N) &#123; long long a = 0, b = 1, c = 0; if (N &lt; 2) &#123; return N; &#125; else &#123; for (long long i = 2; i &lt;= N; ++i) &#123; c = a + b; a = b; b = c; &#125; &#125; return c;&#125;int main()&#123; printf("%lld", fib1(10)); getchar(); return 0;&#125; //此算法最大的优点是不存在重复计算，故效率比递归算法快的多得多。 使用非递归算法求到第n个斐波那契数，是从第2个数开始，将前两个数相加求求后一个数，再将后一个数赋值给前一个数，再计算前两个数相加的结果。依次类推直到第n个数，用n-1个数和n-2个数相加求出结果，这样的好处是，我们只计算了n-1次就求出了结果，即时间复杂度为O(n)；我们以代码中测试数10为例详解求第十个数的过程。当N=10时，进入函数首先判断，然后走下面的分支开始计算。 计算了N-1次，得出了结果所以时间复杂度是O（N）。此函数内部最多时一共开辟了a, b, c, i四个变量空间复杂度是常数，即为O（1）。 第N个斐波那契数的递归算法12345678910111213//递归算法long long fib2(size_t N) &#123; if (N &lt; 2) return N; return fib2(N - 1) + fib2(N - 2);&#125;int main()&#123; printf("%lld", fib2(10)); getchar(); return 0;&#125; 在递归算法中，求解fib2(n)，把它推到求解fib2(n-1)和fib2(n-2)。也就是说，为计算fib2(n)，必须先计算fib2(n-1)和fib2(n-2)，而计算fib2(n-1)和fib2(n-2)，时按照表达式及计算法则，需先计算又必须先计算fib2(n-1)，而fib2(n-1)由fib2(n-2)和fib2(n-3)计算得来，而这之中的和fib2(n-2)由fib2(n-3)和fib2(n-4)计算得来……依次类推，表面上看不出有何复杂度，但是仔细分析可知，每一个计算fib2(n)的分支都会衍生出计算直至(1)和fib(0)，也就是说每个分支都要自己计算数本身到1的斐波那契数列，这样就增加了庞大且冗杂的运算量，还是以10 为例详细计算说明。 图中数字代表第N个斐波那契数，图中没有全部将计算步骤画出来，但是已经足够说明问题，它的每一步计算都被分成计算前两个斐波那契数，以此类推。那么这就形成了一颗二叉树，虽然不是满二叉树，但是我们分析的是最坏时间复杂度，而且只要估算出来递归次数随N增长的趋势即可，故可以近似将它看成满二叉树，其中的节点数就是计算的次数，也就是复杂度，由公式：节点数=$2^h-1$（h为树的高度）可得O（$2^n$）。递归的时间复杂度是： 递归次数*每次递归中执行基本操作的次数，所以时间复杂度是： O($2^N$) 递归最深的那一次所耗费的空间足以容纳它所有递归过程。递归产生的栈侦是要销毁的，所以空间也就释放了，要返回上一层栈侦继续计算+号后面的数，所以它所需要的空间不是一直累加起来的，之后产生的栈侦空间都小于递归最深的那一次所耗费的空间。递归的深度*每次递归所需的辅助空间的个数 ，所以空间复杂度是：O(N) 注意： 1.空间复杂度相比时间复杂度分析要少。2.对于递归算法来说，代码一般都比较简短，算法本身所占用的存储空间较少，但运行时需要占用较多的临时工作单元，并且可能导致栈溢出，当需要计算的数稍大一点，就需要很长的计算时间，因此需要灵活使用递归 参考《大话数据结构》]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[资源相关的编程模式]]></title>
    <url>%2F2020%2F04%2F30%2F%E8%B5%84%E6%BA%90%E7%9B%B8%E5%85%B3%E7%9A%84%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[本文主要总结资源相关的编程模式，以提高大家编程质量，减少遗漏释放资源的可能。 资源这里的资源是一个宽泛的概念。凡是需要成对操作的，都可以视为资源。比如动态内存、文件、锁、中断，等等。我们以函数为单位进行考察，编程中用到的资源大致分为三类，一类是本函数申请，无论本函数成功失败都要释放，例如不保存的动态内存、文件、锁、中断等等；第二类是本函数申请，无论本函数成功失败都不释放，例如发消息的内存；第三类是本函数申请，只有本函数失败才要释放，例如申请了表项资源，后续操作失败才需要回退。第二类从释放函数的角度，也可以看成本函数不申请，无论本函数成功失败都要释放。遗漏释放资源，是编程中经常出现的严重问题。其根本原因是单一函数的结构过于复杂、分支过多，在多个分支中需要考虑资源的释放，非常容易遗漏，尤其是在后期维护修改代码时。所以本文总结了两大类方法用以改善代码质量。 方法一：好的设计根本解决这类问题的方法在于降低函数的复杂度，所以对于新开发的特性在编码前设计时遵从以下原则： 资源与业务分离原则即通过把资源申请和释放之间的业务操作代码封装成函数的方法，将申请、释放资源的函数和使用资源的业务函数分离，使得业务函数中完全不必考虑资源释放的问题。如下图所示： 单一资源原则当一个函数中用到多个资源的时候，通过封装子函数的方法，使得一个函数中只出现一个资源，从而降低复杂度，减少出错的可能。如下图所示： 如果多个资源是并列关系，还可以把多个资源封装成一个大资源，从而在管理时视为一个资源。如下图所示： 唯一释放原则每个函数中只能有一处释放资源的代码。以多操作失败回退为例，通过函数封装使得每个函数中最多只有两步操作，因而只有一处失败回退的代码，从而避免遗漏。如下图所示： 释放规则统一申请资源的函数，对资源释放的规则要统一。当本函数退出时，无论处理成功还是失败，对申请的资源要么都由自己释放，要么不释放。不要出现成功不释放失败才释放的情况。对于发包流程中的内存申请所在的函数，建议设计为成功失败都不释放。如下图所示： 方法二：好的编码然而在实际 项目中，往往是对大量结构复杂的老代码的移植修改。在不允许遵照以上原则重写代码的场合，采用以下编程模式可以尽量减少遗漏释放资源。 1、函数只能有一个出口，使用宏DRV_SAFE_OUT安全退出，不得直接return。也可以直接用在DRV_SAFE_OUT基础上封装好的宏DRV_IF_ERR_SAFE_OUT或DRV_IF_ERR_ASSERT_SAFE_OUT（用于需要打印断言的场合）2、函数末尾必须有名为“SAFE_OUT”的goto标签，标签后的代码对本函数所有需要释放或回退的资源集中处理。 出口宏的封装Talk is cheap. Show you the code：对于有返回值的函数，宏封装如下：1234567891011121314151617181920212223/* 安全退出当前函数，函数返回值变量的命名自定，适用于功能性返回值 */#define DRV_SAFE_OUT(retName, retOut) \ (retName) = (retOut); \ goto SAFE_OUT /* 如果errCondition成立则打印信息并安全退出当前函数，函数返回值变量的命名自定，适用于功能性返回值 */#define DRV_IF_ERR_SAFE_OUT(errCondition, retName, retOut, icLevel, args...) \ if (errCondition) \ &#123; \ printk((icLevel)##args); \ (retName) = (retOut); \ goto SAFE_OUT; \ &#125; /* 如果errCondition成立则打印信息和断言并安全退出当前函数，函数返回值变量的命名自定，适用于功能性返回值 */#define DRV_IF_ERR_ASSERT_SAFE_OUT(errCondition, retName, retOut, icLevel, args...) \ if (errCondition) \ &#123; \ printk((icLevel)##args); \ assert(BOOL_FALSE); \ (retName) = (retOut); \ goto SAFE_OUT; \ &#125;对于无返回值的函数，宏封装如下：1234567891011121314151617181920/* 安全退出当前函数，函数返回值变量的命名自定，适用于功能性返回值 */#define DRV_SAFE_OUT2 \ goto SAFE_OUT /* 如果errCondition成立则打印信息并安全退出当前函数，适用于无返回值场合 */#define DRV_IF_ERR_SAFE_OUT2(errCondition, icLevel, args...) \ if (errCondition) \ &#123; \ printk((icLevel)##args); \ goto SAFE_OUT; \ &#125; /* 如果errCondition成立则打印信息和断言并安全退出当前函数，适用于无返回值场合 */#define DRV_IF_ERR_ASSERT_SAFE_OUT2(errCondition, icLevel, args...) \ if (errCondition) \ &#123; \ printk((icLevel)##args); \ assert(BOOL_FALSE); \ goto SAFE_OUT; \ &#125; 内存资源的释放带返回值的函数释放函数有返回值，无打印输出信息，如下图： 函数有返回值，有打印输出信息，如下图： 不带返回值的函数释放函数无返回值，无打印输出信息，如下图： 函数无返回值，有打印输出信息，如下图： 锁和信号量的释放实现分析此处也是该处总结的重点。为了统一释放锁和信号量，需要考虑如下几个问题： 1、一个函数里可能用到不止一个锁或者信号量，如何做到在函数出口全部都能释放呢？2、锁和信号量的种类很多，函数出口释放的时候如何知道你用哪个接口去释放呢？ 首先，要想释放一个锁（或信号量），必须要知道锁（或信号量）的地址以及解锁（释放信号量）函数。另外，对于spin_lock_irqsave(lock, flags)，获得自旋锁的同时把标志寄存器的值保存到变量flags中并失效本地中断。此时还需要一个存储寄存器值的变量。所以我们可以定义一个结构体： 1234567891011/* 各种锁(信号量)通用的函数原型 */typedef VOID (* DRV_LOCK_PF)(const VOID*, ULONG);/* 各种锁(信号量)通用的控制结构 */typedef struct tagDrvLock&#123; VOID *pLock; /* 锁的地址 */ DRV_LOCK_PF pfUnlock; /* 释放锁的函数 */ ULONG ulData; /* 释放锁的函数参数 */&#125;DRV_LOCK_S; 那么接下来，我们对所有锁（或信号量）的释放函数按照DRV_LOCK_PF的函数原型进行封装，如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* 按照DRV_LOCK_PF原型对锁释放函数进行封装 */VOID DRV_SPIN_Unlock(const VOID *pLock, ULONG ulData)&#123; (VOID)ulData; spin_unlock((spinlock_t *)pLock); return;&#125;VOID DRV_WRITE_Unlock(const VOID *pLock, ULONG ulData)&#123; (VOID)ulData; write_unlock((rwlock_t *)pLock); return;&#125;VOID DRV_READ_Unlock(const VOID *pLock, ULONG ulData)&#123; (VOID)ulData; read_unlock((rwlock_t *)pLock); return;&#125;VOID DRV_READ_UnlockBh(const VOID *pLock, ULONG ulData)&#123; (VOID)ulData; read_unlock_bh((rwlock_t *)pLock); return;&#125;VOID DRV_WRITE_UnlockBh(const VOID *pLock, ULONG ulData)&#123; (VOID)ulData; write_unlock_bh((rwlock_t *)pLock); return;&#125;VOID DRV_SPIN_UnlockIrqRestore(const VOID *pLock, ULONG ulData)&#123; spin_unlock_irqrestore((spinlock_t *)pLock, ulData); return;&#125;VOID DRV_SPIN_UnlockBh(const VOID *pLock, ULONG ulData)&#123; (VOID)ulData; spin_unlock_bh((spinlock_t *)pLock); return;&#125;VOID DRV_Up(const VOID *pLock, ULONG ulData)&#123; (VOID)ulData; up((struct semaphore *)pSem); return;&#125; 接下来，就是确认函数使用锁（或信号量）的数量，为每个锁分配一个DRV_LOCK_S结构，用以释放。在函数内部实现定义变量时调用，如下：1234/* 声明本函数用到的锁的数量，包括各种锁和信号量 */#define DRV_DECLARE_LOCKS(lockCnt) \ DRV_LOCK_S astLocks_[lockCnt] = &#123;&#123;0&#125;&#125;; \ UINT uiLockCnt_ = 0 最后，我们就是要将锁（或信号量）和DRV_LOCK_S关联起来，加锁时入栈，解锁时出栈：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156/* 已获取的锁(信号量)入栈 */#define DRV_LOCK_PUSH(stack, cnt, pLock, pfUnlock, data) \ stack[cnt].pLock = pLock; \ stack[cnt].pfUnlock = pfUnlock; \ stack[cnt].ulData = data; \ (cnt)++; /* 指定的锁(信号量)出栈，如果不是栈顶要搬移 */static inline VOID DRV_LOCK_Pop(IN const VOID *pLock, INOUT DRV_LOCK_S *pstStack, INOUT UINT *puiCnt)&#123; UINT uiTop = *puiCnt - 1; if (pLock != pstStack[uiTop].pLock) &#123; ULONG ulLoop; for (ulLoop = 0; ulLoop &lt; uiTop; ulLoop++) &#123; if (pLock == pstStack[uiLoop].pLock) &#123; memcpy(&amp;(pstStack[uiLoop]), &amp;(pstStack[ulLoop + 1]), (*puiCnt - (ulLoop + 1)) * sizeof(DRV_LOCK_S)); break; &#125; &#125; DBGASSERT(ulLoop &lt; uiTop); &#125; (*puiCnt)--; return;&#125;/* 和spin_lock用法一样 */#define DRV_SPIN_LOCK(pLock) \&#123; \ spin_lock(pLock); \ DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pLock, DRV_SPIN_Unlock, 0); \&#125;/* 和spin_unlock用法一样 */#define DRV_SPIN_UNLOCK(pLock) \&#123; \ DRV_SPIN_Unlock(pLock, 0UL); \ DRV_LOCK_Pop(pLock, astLocks_, &amp;uiLockCnt_); \&#125;/* 和spin_lock_bh用法一样 */#define DRV_SPIN_LOCK_BH(pLock) \&#123; \ spin_lock_bh(pLock); DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pLock, DRV_SPIN_UnlockBh, 0); \&#125;/* 和spin_unlock_bh用法一样 */#define DRV_SPIN_UNLOCK_BH(pLock) \&#123; \ DRV_SPIN_UnlockBh(pLock, 0UL); \ DRV_LOCK_Pop(pLock, astLocks_, &amp;uiLockCnt_); \&#125;/* 和spin_lock_irqsave用法一样 */#define DRV_SPIN_LOCK_IRQSAVE(pLock, flag) \&#123; \ spin_lock_irqsave(pLock, flag); DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pLock, DRV_SPIN_UnlockIrqRestore, flag); \&#125;/* 和read_lock用法一样 */#define DRV_READ_LOCK(pLock) \&#123; \ read_lock(pLock); \ DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pLock, DRV_READ_Unlock, 0); \&#125;/* 和read_unlock用法一样 */#define DRV_READ_UNLOCK(pLock) \&#123; \ DRV_READ_Unlock(pLock, 0UL); \ DRV_LOCK_Pop(pLock, astLocks_, &amp;uiLockCnt_); \&#125;/* 和read_lock_bh用法一样 */#define DRV_READ_LOCK_BH(pLock) \&#123; \ read_lock_bh(pLock); \ DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pLock, DRV_READ_UnlockBh, 0); \&#125;/* 和read_unlock_bh用法一样 */#define DRV_READ_UNLOCK_BH(pLock) \&#123; \ DRV_READ_UnlockBh(pLock, 0UL); \ DRV_LOCK_Pop(pLock, astLocks_, &amp;uiLockCnt_); \&#125;/* 和write_lock用法一样 */#define DRV_WRITE_LOCK(pLock) \&#123; \ write_lock(pLock); \ DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pLock, DRV_WRITE_Unlock, 0); \&#125;/* 和write_unlock用法一样 */#define DRV_WRITE_UNLOCK(pLock) \&#123; \ DRV_WRITE_Unlock(pLock, 0UL); \ DRV_LOCK_Pop(pLock, astLocks_, &amp;uiLockCnt_); \&#125;/* 和write_lock_bh用法一样 */#define DRV_WRITE_LOCK_BH(pLock) \&#123; \ write_lock_bh(pLock); \ DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pLock, DRV_WRITE_UnlockBh, 0); \&#125;/* 和write_unlock_bh用法一样 */#define DRV_WRITE_UNLOCK_BH(pLock) \&#123; \ DRV_WRITE_UnlockBh(pLock, 0UL); \ DRV_LOCK_Pop(pLock, astLocks_, &amp;uiLockCnt_); \&#125;/* 和down用法一样 */#define DRV_DOWN(pSem) \&#123; \ down(pSem); \ DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pSem, DRV_Up, 0); \&#125;/* 和up用法一样 */#define DRV_UP(pSem) \&#123; \ DRV_Up(pSem, 0UL); \ DRV_LOCK_Pop(pSem, astLocks_, &amp;uiLockCnt_); \&#125;/* 和down_timeout用法不同，返回值作为出参 */#define DRV_DOWN_TIMEOUT(pSem, time, ret) \ ret = down_timeout(pSem, time); if (0 == ret) \ &#123; \ DRV_LOCK_PUSH(astLocks_, uiLockCnt_, pSem, DRV_Up, 0); \ &#125; /* 释放本函数所有已获取的锁(信号量)，后进先出 */#define DRV_UNLOCK_ALL \&#123; \ UINT uiLoop, uiTop; \ for (uiLoop = 0; uiLoop &lt; uiLockCnt_; uiLoop++) &#123; \ uiTop = (uiLockCnt_ - 1) - uiLoop; \ astLocks_[uiTop].pfUnlock(astLocks_[uiTop].pLock, astLocks_[uiTop].ulData); \ &#125; \ uiLockCnt_ = 0; \&#125;]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>C语言</tag>
        <tag>操作系统</tag>
        <tag>嵌入式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHY管理接口MDIO]]></title>
    <url>%2F2019%2F11%2F20%2FPHY%E7%AE%A1%E7%90%86%E6%8E%A5%E5%8F%A3MDIO%2F</url>
    <content type="text"><![CDATA[本文主要总结MDIO接口相关知识。 MII接口MII（Media Independent Interface）(介质无关接口)或称为媒体独立接口，MII接口是MAC与PHY连接的标准接口。它是IEEE802.3的以太网行业标准。MII接口提供了MAC与PHY之间、PHY与STA（Station Management）之间的互联技术。“媒体独立”表明在不对MAC硬件重新设计或替换的情况下，任何类型的PHY设备都可以正常工作。它是一种用于将不同的PHY与相同的网络控制器（MAC）相连接的通用总线。 STA(Station management entity)：管理实体，一般为MAC或CPU，通过SMI（Serial Manage Interface）对PHY的行为、状态进行管理和控制，而具体管理和控制动作是通过读写PHY内部的寄存器实现的。 MII和MDIO关系MII接口包括一个数据接口和一个MAC和PHY之间的管理接口（MDIO接口）。数据接口包括分别用于发送器和接收器的两条独立信道，每条信道都有自己的数据时钟和控制信号。管理接口是个双信号接口：一个是时钟信号，一个是数据信号。通过管理接口，上层能监视和控制PHY。其中时钟信号就是MDC，它是由MAC输出，是非周期性的，即不要求提供固定频率的时钟，对于PHY芯片则作为输入，在上升沿触发MDIO的读写。MDC的时钟频率可以是DC-2.5MHz，即最小的时钟周期为400ns。数据信号就是MDIO，它是一根双向的数据线，MAC作为master，PHY作为slave。在写PHY寄存器的时候，由MAC驱动MDIO向PHY写入数据；在读PHY寄存器时，前半段由MAC驱动发送寄存器地址，后半段由PHY驱动回复寄存器的值。以10M，100M端口为例，MII和MDIO结构图如下： IEEE802.3在两个章节定义了PHY的管理接口： 1、22.2.4 Management functions2、45. Management Data Input/Output (MDIO) Interface Clause22和Clause 45Clause22定义GE及以下速率（10/100/1000M）PHY的管理接口；Clause45定义10G及以上速率PHY的管理接口；STA通过管理接口对PHY寄存器进行读写操作。 Clause 22帧Clause 22帧格式： 1）PREPRE即preamble。MAC访问PHY寄存器之前，连续发送32个”1“，用于和PHY进行同步。 2）STST即Start of frame，是2个固定的比特0和1。 3）OPOP即Operation Code。读操作的操作码是10，写操作的操作码是01。 4）PHYADPHYAD即PHY address，表示5个bit位的PHY地址。PHY地址是由硬件连接决定的。硬件设计时，把PHY芯片的引脚电平上拉或者下拉，就可以设定PHY的地址。首先发送接收高位地址。 5）REGADREGAD即Register Address，表示PHY内部的寄存器地址。MII管理接口中，寄存器地址是5位的。首先发送接收高位地址。 6）TATA即Turn Around。寄存器地址字段和管理帧的数据字段之间有2bit的转换间隙，以避免读操作时冲突。读操作的TA域从高阻态变为0，写操作的TA域则是从1变为0。如下图所示： 高阻态是一个数字电路里常见的术语，指的是电路的一种输出状态，既不是高电平也不是低电平，如果高阻态再输入下一级电路的话，对下级电路无任何影响，和没接一样，如果用万用表测的话有可能是高电平也有可能是低电平，随它后面接的东西定的。 7）DATA数据域为16bit，和PHY寄存器的宽度一致。读操作中，DATA域是从PHY层读到的数据；写操作中，DATA域是要写入PHY寄存器的值。 Clause 22限制由上可知，Clause 22只有5bit的寄存器空间和PHY地址空间，这样导致能访问的PHY寄存器只有32个。千兆以下的PHY比较简单，只有32个寄存器，MAC通过Clause 22管理接口访问这些PHY寄存器已经足够，但是10G以上的PHY比较复杂，PHY层被划分为多个子层，PCS子层、PMA子层、PMD子层，Clause 22很难满足要求。 Clause 22扩展前期，对于PHY上述限制，采用的一个比较通用的做法是单独设立一个PAGE寄存器，然后将寄存器映射到不同的PAGE上，每个PAGE是32Word空间。以88E1111为例，我们需要首先在Page寄存器22写值，选择对应的Page，然后再访问该Page上的寄存器。虽然这个方案暂时解决了寄存器空间不够的问题，但是由于IEEE没有对应的规范，各个厂商实现的都不一样，驱动需要根据不同的PHY芯片写不同的接口代码。88E1111寄存器如下图： Clause 45终于在2000年的时候IEEE发布了IEEE 802.3 Clause 45规范来解决这个问题。 Clause 45帧格式： Clause45 管理接口硬件上和Clause 22管理接口一致，但是管理帧结构发生了变化。通过MDIO接口访问PHY寄存器时，需要知道端口地址、MMD设备地址和寄存器地址。和Clause 22管理接口相比，Clause 45接口的读和写操作变复杂了，操作一个寄存器需要完成两步，首先要传送寄存器地址信息，然后才能读或者写对应的寄存器。和Clause 22管理接口的管理帧相比，Clause 45接口的管理帧的主要差异如下：1）STST即Start of frame。Clause 22管理接口的管理帧的ST域是01，Clause 45接口管理帧中的ST域的值是00。 2）PRTADPRTAD即Port Address。PRTAD和Clause 22管理接口的管理帧的PHY address一致。 3）DEVADDEVED是Device Address，该域是MMD设备的5位ID。这个域对应Clause 22管理接口的管理帧的寄存器地址域。 4）ADDRESS/DATAMDIO接口的地址操作中，这个域用来传送需要访问的寄存器的16位地址。Clause 22管理接口中，寄存器地址只有5位；Clause 45接口中，寄存器地址变为16位。Clause 45接口的读写操作中，这个域是读出或者待写入的数据。Clause 45接口，单个STA通过单个MDIO接口最多可以访问32个PHY，每个PHY最多支持32个MMD，每个MMD最多可支持65536个寄存器。Clause 45结构： MMD(MDIO Manageable Device):MDIO管理设备，通过IEEE802.3标准Clause 45规定的MDIO接口进行管理。在Clause 45接口的定义中，PHY层被划分为多个MMD设备，每个MMD内部的寄存器的地址分配和Clause 22管理接口中的地址类似，不过寄存器的数量多出很多。IEEE 802.3标准规定的MMD设备地址： 读写时序Clause 22读时序： 1、MDIO master 驱动输出前导符，前导符为高电平1。连续发送32个“1”，用于和PHY进行同步。2、发送2bit的固定的启动开始标志，01b3、发送2bit的操作码，读是10b4、发送5bit的Phy addr，通过该地址来识别对应的PHY芯片5、发送5bit的寄存器地址，寻址范围是32 Word6、对于读时序的前半部分由MDIO master侧驱动 ，通过一个高阻态bit time切换到slave驱动，slave驱动后驱动一个bit的07、slave 输出寻址的寄存器和16bit的值8、总线进入高阻态，读时序结束 写时序： 1、MDIO master 驱动输出前导符，前导符为高电平1。连续发生32个“1”，用于和PHY进行同步。2、发送2bit的固定的启动开始标志，01b3、发送2bit的操作码，写是01b4、发送5bit的Phy addr，通过该地址来识别对应的PHY芯片5、发送5bit的寄存器地址，寻址范围是32 Word6、发送2bit固定的周转码，为10b7、输出要写入寄存器的16bit值8、总线进入高阻态，写时序结束 Clause 45设置地址时序： 1、MDIO master驱动输出前导符，前导符为高电平1。连续发送32个“1”，用于和PHY进行同步2、发送2bit的固定的启动开始标志，00b3、发送2bit的操作码，写地址是00b4、发送5bit的Phy addr，通过该地址来识别对应的PHY芯片5、发送5bit的设备地址，寻址范围是32 Word。（可以理解为PHY的二级地址）6、发送2bit固定的周转码，为10b7、发送要写入的16bit的地址值8、总线进入高阻态，写地址时序结束 写时序： 1、MDIO master驱动输出前导符，前导符为高电平1。连续发生32个“1”，用于和PHY进行同步2、发送2bit的固定的启动开始标志，00b3、发送2bit的操作码，写操作是01b4、发送5bit的Phy addr，通过该地址来识别对应的PHY芯片5、发送5bit的设备地址，寻址范围是32 Word。（可以理解为PHY的二级地址）6、发送2bit固定的周转码，为10b7、发送要写入的16bit的地址值8、总线进入高阻态，写时序结束 读时序： 1、MDIO master驱动输出前导符，前导符为高电平1。连续发送32个“1”，用于和PHY进行同步2、发送2bit的固定的启动开始标志，00b3、发送2bit的操作码，读操作是11b4、发送5bit的Phy addr，通过该地址来识别对应的PHY芯片5、发送5bit的设备地址，寻址范围是32 Word。（可以理解为PHY的二级地址）6、发送2bit固定的周转码，为Z0b7、slave输出16bit的寄存器值8、总线进入高阻态，读时序结束 增量读时序： 1、MDIO master驱动输出前导符，前导符为高电平1。连续发送32个“1”，用于和PHY进行同步2、发送2bit的固定的启动开始标志，00b3、发送2bit的操作码，对于增量读操作是10b4、发送5bit的Phy addr，通过该地址来识别对应的PHY芯片5、发送5bit的设备地址，寻址范围是32 Word。（可以理解为PHY的二级地址）6、发送2bit固定的周转码，为Z0b7、slave输出16bit的寄存器值（每次都较上一次多偏移一单位地址）8、总线进入高阻态，增量读时序结束 增量读：就是连续读出一段空间的地址，这时候先通过设置地址的时序写寄存器的地址，再依次重复调用增量读命令去读寄存器，每次在接收到增量读地址帧并完成读操作后，MMD将地址寄存器递增1。直到读完该空间最后一个寄存器。 总结 1、Clause 45寄存器地址从5bit扩展到16bit，既可以访问到65536个寄存器2、Clause 45引入了MMD概念，每个PHY最多可支持32个MMD3、Clause 22只需要1帧就可以完成读写，而Clause 45需要2帧（第一次发送地址协议帧指定寄存器，第二次发送帧去读写数据）才可以完成读写]]></content>
      <categories>
        <category>以太网</category>
      </categories>
      <tags>
        <tag>嵌入式</tag>
        <tag>以太网</tag>
        <tag>IEEE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程睡眠]]></title>
    <url>%2F2019%2F11%2F16%2F%E8%BF%9B%E7%A8%8B%E7%9D%A1%E7%9C%A0%2F</url>
    <content type="text"><![CDATA[本文主要总结引起进程睡眠的相关知识。 进程睡眠简介进程睡眠的含义为：当前进程停止运行，系统将进行任务调度使另外一个任务运行。当唤醒睡眠的条件出现时，该进程将被唤醒，等待任务调度时恢复执行。睡眠函数的核心在于触发任务调度，即调用schedule()函数，使系统当前运行的进程发生切换。 引起睡眠的操作 哪些流程禁止调用睡眠函数上下文是什么上下文是从英文context翻译过来，指的是一种环境。相对于进程而言，就是进程执行时的环境；具体来说就是各个变量和数据，包括所有的寄存器变量、进程打开的文件、内存信息等。那为什么会有上下文呢？在介绍这个话题前，我们先了解一下下面几个知识。 内核空间和用户空间我们知道现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟内存空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对Linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。每个进程可以通过系统调用进入内核，因此，Linux内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有4G字节的虚拟空间。空间分配如下图所示： 有了用户空间和内核空间，整个Linux内部结构可以分为三个部分，从最底层到最上层依次是：硬件—&gt;内核空间—&gt;用户空间。如下图所示： 特权级Intel X86架构的CPU一共有0~3四个特权级，0级最高，3级最低，ARM架构也有不同的特权级，硬件上在执行每条指令时都会对指令所具有的特权级做相应的检查。硬件已经提供了一套特权级使用的相关机制，软件自然要好好利用，这属于操作系统要做的事情，对于UNIX/LINUX来说，只使用了0级特权级别和3级特权级别，即最高最低特权级。也就是说在UNIX/LINUX系统中，一条工作在0级特权级的指令具有了CPU能提供的最高权力，而一条工作在3级特权的指令具有CPU提供的最低或者说最基本权力。以上是从CPU执行指令角度理解特权，其实虚拟地址到物理地址映射有mmu硬件实现，即分页机制是硬件对分页的支持，进程中有页表数据结构指向用户空间和内核空间，使用户态和内核态访问内存空间不同。 现在我们从特权级的调度来理解用户态和内核态就比较好理解了，当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在内核态；反之，当程序运行在0级特权级上时，就可以称之为运行在内核态。虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。运行在用户态的程序不能访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的。在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。Linux进程的4GB地址空间，3G-4G部分大家是共享的，是内核态的地址空间，这里存放着整个内核的代码和所有的内核模块，以及内核所维护的数据。用户运行一个程序，该程序所创建的进程开始是运行在用户态的，如果要执行文件操作，网络数据发送等操作，必须通过write，send等系统调用，这些系统调用会调用内核中的代码来完成操作，这时，必须切换到Ring0，然后进入3GB-4GB中的内核地址空间去执行这些代码来完成操作，完成后，切换回Ring3，回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。 为什么会有上下文系统的两种不同运行状态，才有了上下文的概念。CPU对上下文环境进一步细分，因此有：以下三种状态： 内核态，运行于进程上下文，内核代表进程运行于内核空间。内核态，运行于中断上下文，内核代表硬件运行于内核空间。用户态，运行于用户空间。 用户空间的应用程序，如果想请求系统服务，比如操作某个物理设备，映射设备的地址到用户空间，必须通过系统调用来实现。（系统调用是操作系统提供给用户空间的接口函数）。通过系统调用，用户空间的应用程序就会进入内核空间，由内核代表该进程运行于内核空间，这就涉及到上下文的切换，用户空间和内核空间具有不同的地址映射，通用或专用的寄存器组，而用户空间的进程要传递很多变量、参数给内核，内核也要保存用户进程的一些寄存器、变量等，以便系统调用结束后回到用户空间继续执行。交互如下图所示： 进程上下文所谓的进程上下文，就是一个进程在执行的时候，CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。 一个进程的上下文可以分为三个部分：用户上下文、寄存器上下文以及系统级上下文： 用户级上下文：正文、数据、用户堆栈以及共享存储区；寄存器上下文：通用寄存器、程序寄存器（IP）、处理器状态寄存器（EFLAGS）、栈指针（ESP）；系统级上下文：进程控制块task_struct、内存管理信息（mm_struct、vm_area_struct、pgd、pte）、内核栈。 当发生进程调度时，进行进程切换就是上下文切换（context switch）。操作系统必须对上面提到的全部信息进行切换，新调度的进程才能运行。而系统调用运行的是模式切换（mode switch）。模式切换与进程切换比较起来，容易很多，而且节省时间，因为模式切换最主要的任务只是切换进程寄存器上下文的切换。在进程上下文中，可以用current宏关联当前进程，也可以睡眠，也可以调用调度程序。 中断上下文硬件通过触发信号，向CPU发送中断信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。所以，“中断上下文”就可以理解为硬件传递过来的这些参数和内核需要保存的一些环境，主要是被中断的进程的环境。内核进入中断上下文是因为中断信号而导致的中断处理或软中断。而中断信号的发生是随机的，中断处理程序及软中断并不能事先预测发生中断时当前运行的是哪个进程，所以在中断上下文中引用current是可以的，但没有意义。在中断上下文，通常都会始终占用CPU（当然中断可以嵌套，但我们一般不这样做），不可以被打断。不可以睡眠或者释放CPU。 为什么中断上下文不能调用可以睡眠的函数呢？中断的处理流程： 1.进入中断处理程序2.保存关键上下文3.开中断（sti指令）4.进入中断处理程序的handler5.关中断（cli指令）6.写EOI寄存器（表示中断处理完成）7.开中断 硬中断对应于上图中的1、2、3步骤，在这几个步骤中，所有中断是被屏蔽的，如果在这个时候睡眠了，操作系统不会收到任何中断（包括时钟中断），系统就基本处于瘫痪状态（例如调度器依赖的时钟节拍没有等等……） 软中断对应上图的4（当然，准确的说应该是4步骤的后面一点）。这个时候不能睡眠的关键是因为上下文。操作系统以进程调度为单位，进程运行在进程的上下文中，以进程描述符作为管理的数据结构task_struct。进程可以睡眠的原因是操作系统可以切换不同进程的上下文，进行调度操作，这些操作都以进程描述符为支持。中断运行在中断上下文，没有一个所谓的中断描述符来描述它，它不是操作系统调度的单位。一旦在中断上下文中睡眠， 首先无法切换上下文（因为没有中断描述符，当前上下文的状态得不到保存），其次，没有人来唤醒它，因为它不是操作系统的调度单位。此外，中断的发生是非常非常频繁的，在一个中断睡眠期间，其它中断发生并睡眠了，那很容易就造成中断栈溢出导致系统崩溃。如果上述条件满足了（也就是有中断描述符，并成为调度器的调度单位，栈也不溢出了，理论上是可以做到中断睡眠的），中断是可以睡眠的，但会引起很多问题：例如，你在时钟中断睡眠了，那操作系统的时钟就乱了，调度器也就失去了依据；例如，你在一个IPI（处理器间中断）中，其他CPU都在死循环等你答复，你却睡眠了，那其他处理器也不工作了；例如，你在一个DMA中断中睡眠了，上面的进程还在同步的等待I/O的完成，性能就大大降低了……还可以举出很多例子。所以，中断是一种紧急事务，需要操作系统立即处理，不是不能做到睡眠，是它没有理由睡眠。不过，在Linux调度器的具体实现的时候，检测到了在中断上下文中调度schedule函数也并没有强制Linux进入panic，可能是linux开发者认为一个好的内核调度器无论如何也尽自己最大的努力让系统运行下去吧。但是，在厂商自己提供的内核中，往往修改调度器行为，在中断上下文中检测到调度就直接panic了，对于内核开发者而言，这样更好，可以尽早的发现问题。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>嵌入式</tag>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F10%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C语言</tag>
      </tags>
  </entry>
</search>
